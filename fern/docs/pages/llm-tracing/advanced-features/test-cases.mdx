---
subtitle: Creating test cases in your traces to run evaluations on-the-fly
slug: llm-tracing/advanced-features/test-cases
---

## Overview

Confident AI allows you to [run evaluations](/docs/llm-tracing/evaluations#online-evals-for-traces) on your spans and traces, which requires you to set test case parameters in `update_current_span` and `update_current_trace`.

<Note>
Each metric requires different test case parameters. For detailed information on required test case parameters for each metric, refer to the [official DeepEval documentation](https://deepeval.com/docs/metrics-introduction).
</Note>

## Test Case Parameters

<Tabs>
    <Tab title="Python" language="python" >
        Both `update_current_span` and `update_current_trace` accept 7 **OPTIONAL** test case parameters:

        - `input`: The input to your LLM app
        - `output`: The output of your LLM app
        - `expected_output`: The expected output of your LLM app
        - `retrieval_context`: A list of strings representing the retrieved text chunks from a retrieval system
        - `context`: A list of strings representing the ideal retrieved text chunks provided from a retrieval system
        - `tools_called`: A list of `ToolCall` objects representing the tools called by your LLM app
        - `expected_tools`: A list of `ToolCall` objects representing the expected tools to be called by the LLM app

    </Tab>
    <Tab title="TypeScript" language="typescript" >
        Both `updateCurrentSpan` and `updateCurrentTrace` accept 7 **OPTIONAL** test case parameters:

        - `input`: The input to your LLM app
        - `output`: The output of your LLM app
        - `expectedOutput`: The expected output of your LLM app
        - `retrievalContext`: A list of strings representing the retrieved text chunks from a retrieval system
        - `context`: A list of strings representing the ideal retrieved text chunks provided from a retrieval system
        - `toolsCalled`: A list of `ToolCall` objects representing the tools called by your LLM app
        - `expectedTools`: A list of `ToolCall` objects representing the expected tools to be called by the LLM app

    </Tab>
</Tabs>

<Tip>
The **input** and **output** accept `Any` type for visualization purposes, but we recommend setting them as strings for running evaluations.
</Tip>

## Set Span Test Case Parameters

You can set span-level test case parameters in the `update_current_span` function:

<Tabs>
    <Tab title="Python" language="python">
            ```python title="main.py" {6}
            from deepeval.tracing import observe, update_current_span
            from deepeval.test_case import ToolCall

            @observe()
            def tool_calling_agent(query: str):
                update_current_span(
                    input=query,
                    output="Agent response",
                    tools_called=[ToolCall(name="web_search", input_parameters={"query": query})],
                )
                return "Agent response"

            tool_calling_agent("What is weather in San Francisco?")
            ```
    </Tab>
    <Tab title="TypeScript" language="typescript">
            ```js title="index.ts" {5}
            import { observe, updateCurrentSpan } from "deepeval-ts/tracing";
            import { ToolCall } from "deepeval-ts";

            const toolCallingAgent = (query: string) => {
                updateCurrentSpan({
                    input: query,
                    output: "Agent response",
                    toolsCalled: [new ToolCall({ name: "web_search", inputParameters: { query: query } })],
                });
                return "Agent response";
            };

            const observedToolCallingAgent = observe({ fn: toolCallingAgent });
            observedToolCallingAgent("What is weather in San Francisco?");
            ```
    </Tab>

</Tabs>

## Set Trace Test Case Parameters

You can set trace-level test case parameters in the `update_current_trace` function.

<Info>
`update_current_trace` can be set multiple times at any point in your code under the `observe` decorator, which is useful when a parameter is only accessible in specific parts of your code.
</Info>

<Tabs>
    <Tab title="Python" language="python">
            ```python title="main.py" {19}
            from openai import OpenAI
            from deepeval.tracing import observe, update_current_trace

            client = OpenAI()

            @observe()
            def retriever(query: str):
                retrieved_chunks = ["chunk1", "chunk2"]
                update_current_trace(retrieval_context=retrieved_chunks)
                return "\n".join(retrieved_chunks)

            @observe()
            def llm_app(query: str):
                retrieval_context = retriever(query)
                res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": query + retrieval_context}]
                ).choices[0].message.content
                update_current_trace(input=query, output=res)
                return res

            llm_app("What is weather typically like in San Francisco?")
            ```
    </Tab>
    <Tab title="TypeScript" language="typescript">
            ```js title="index.ts" {21}
            import OpenAI from "openai";
            import { observe, updateCurrentTrace } from "deepeval-ts/tracing";

            const client = new OpenAI();

            const observedRetriever = observe({
                fn: (query: string) => {
                    const retrieved_chunks = ["chunk1", "chunk2"];
                    updateCurrentTrace({ retrievalContext: retrieved_chunks });
                    return retrieved_chunks.join("\n");
                },
            });

            const observedLLMApp = observe({
                fn: async (query: string) => {
                    const retrieval_context = observedRetriever(query);
                    const res = await client.chat.completions.create({
                        model: "gpt-4o",
                        messages: [ { role: "user", content: query + retrieval_context } ],
                    });
                    updateCurrentTrace({ input: query, output: res.choices[0].message.content });
                    return res.choices[0].message.content;
                },
            });

            observedLLMApp("What is weather typically like in San Francisco?");
            ```
    </Tab>

</Tabs>
